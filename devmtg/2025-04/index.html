<!--#include virtual="../../header.incl" -->

<div class="www_sectiontitle">2025 EuroLLVM Developers' Meeting</div>
<div style="float:left; width:68%;">
<br>
<div style="width:100%;">

<table><tr>
<td valign="top">
<ol>
        <li><a href="#about">About</a></li>
        <li><a href="#program">Program</a></li>
        <li><a href="#coc">Code of Conduct</a></li>
        <li><a href="#contact">Contact</a></li>
</ol>
</td>

<td valign="top">
<ul>
   <li><b>Conference Dates</b>: April 15-16, 2025 (Pre-Conference workshops April 14)</li>
   <li><b>Location</b>: <a href="https://www.berlin.intercontinental.com/">InterContinental Berlin, Berlin, Germany</a></li>
   <li><b>Event Site: <a href="https://llvm.swoogo.com/2025eurollvm/home">https://llvm.swoogo.com/2025eurollvm/home</a> </li>
</ul>
</td>
</tr></table>
</div>

<div class="www_sectiontitle" id="about">About</div>

<p>The Euro LLVM Developers' Meeting is a bi-annual gathering of the entire LLVM Project community. The conference is organized by the LLVM Foundation and many volunteers within the LLVM community. Developers and users of LLVM, Clang, and related subprojects will enjoy attending interesting talks, impromptu discussions, and networking with the many members of our community. Whether you are a new to the LLVM project or a long time member, there is something for each attendee.
</p>
<p>To see the agenda and speakers please visit the Event Site here: <a href="https://llvm.swoogo.com/2025eurollvm">https://llvm.swoogo.com/2025eurollvm</a></p>
<p>What can you can expect at an LLVM Developers' Meeting?
<dl>
<dt><b>Technical Talks</b></dt>
<dd>These 20-30 minute talks cover all topics from core infrastructure talks, to project's using LLVM's infrastructure. Attendees will take away technical information that could be pertinent to their project or general interest.</li>
<br></dd>

<dt><b>Tutorials</b></dt>
<dd>Tutorials are 50-60 minute sessions that dive down deep into a technical topic. Expect in depth examples and explanations.</dd>

<dt><b>Lightning Talks</b></dt>
<dd>These are fast 5 minute talks that give you a taste of a project or topic. Attendees will hear a wide range of topics and probably leave wanting to learn more.</dd>

<dt><b>Quick Talks</b></dt>
<dd>Quick 10 minute talks that dive a bit deeper into a topic, but not as deep as a Technical Talk.</dd>

<dt><b>Student Technical Talks</b></dt>
<dd>Graduate or Undergraduate students present their work using LLVM.</dd>

<dt><b>Panels</b></dt>
<dd>Panels are 45-60 minute sessions that feature a panel of experts discussing a topic. Attendees will learn from the panelists and have a chance to ask questions.</dd>
</dl>

<p>What types of people attend?
<ul>
<li>Active developers of projects in the LLVM Umbrella
(LLVM core, Clang, LLDB, libc++, compiler_rt, flang, lld, MLIR, etc).</li>
<li>Anyone interested in using these as part of another project.</li>
<li>Students and Researchers</li>
<li>Compiler, programming language, and runtime enthusiasts.</li>
<li>Those interested in using compiler and toolchain technology in novel
and interesting ways.</li>
</ul>

<p>The EuroLLVM Developers' Meeting strives to be the <i>best conference</i> to meet other LLVM developers and users.</p>

<p>For future announcements or questions: Please visit the LLVM Discourse forums. Most posts are in the Announcements or Community categories and tagged with eurollvm.</p> 

<div class="www_sectiontitle" id="program">Program</div>

<p>
<b>Keynotes:</b>
</p>

<p>
A Recipe for Eliminating Entire Classes of Memory Safety Vulnerabilities in C and C++ [ Video ]<br>
<i>Devin Coughlin</i><br><br>
This talk describes a "recipe" for developing compiler-backed secure programming models that
eliminate entire classes of memory-safety security vulnerabilities in C-based languages. We will
explain how we used this recipe to design Clang's -fbounds-safety language extension, Clang's -
Wunsafe-buffer-usage programming model and the Clang Static Analyzer's WebKit smart pointer
checks. We will also describe the need for new Clang-based static analysis infrastructure to enable
faster, lower-developer-cost adoption of these programming models.
</p>

<p>
Deep Dive into the MLIR to LLVM IR Translation Mechanism [ Video ]  [ <a href="slides/keynote/zinenko_deep_dive.pdf">Slides</a> ]<br>
<i>Alex Zinenko</i><br><br>
MLIR is now an inherent part of the LLVM compiler infrastructure, but what connects the two
representations? In theory, the conceptual similarity of the core representation. In practice, a highly
important, yet often overlooked, module translation subsystem. This talk will present the multi-
dialect translation mechanism available in MLIR to target LLVM IR, explain how to use it for a custom
dialect, and argue why it may not always be the best idea. It will also discuss interoperability
between MLIR and LLVM IR functions, including ABI for built-in types and calling conventions.
</p>

<p><b>Technical Talks:</b></p>

<p>
berlin: symbol lookup error: libeurollvm.so.2025: undefined symbol: _Z11abiBreakingChange [ Video ] [ <a href="slides/technical_talk/daniel_lookup.pdf">Slides</a> ]<br>
<i>Domján Dániel</i><br>
<br>
A lightweight talk presenting a Clang Tool that detects binary compatibility breaking changes in C++
libraries. Edit: the title is a valid error message produced by such a change
</p>

<p>
Integration of LLVM-JIT Compiler with Interpreter and manually prepared machine code snippets [ Video ] [ <a href="slides/technical_talk/auberer_integration.pdf">Slides</a> ]<br>
<i>Marc Auberer, Lukas Rapp</i><br>
<br>
In this talk, we will demonstrate how LLVM-based JIT compilation, an interpreter, and manually
prepared machine code snippets can be integrated to create a unified SQL query execution engine
with low latency and high throughput.
</p>

<p>
Debugging Regressions: Interactive Differential Debugging [ Video ] [ <a href="slides/technical_talk/cariappa_debugging.pdf">Slides</a> ]<br>
<i>Vipul Cariappa, Martin Vassilev</i><br>
<br>
Software systems have become increasingly complex, with millions of lines of code developed by
large teams, making debugging challenging. Differential debugging, which compares a system's
current version to a previous one, helps isolate regressions, but current methods lack integration
between the two versions being debugged. The presentation introduces Interactive Differential
Debugging (IDD), a tool that improves this process by automating the identification of irrelevant
execution paths and providing tools for comparing execution states between two versions. IDD
integrates with LLDB, offering a streamlined way to detect functional or performance regressions.
</p>

<p>
How to bring your Neural Network into Upstream MLIR Dialects [ Video ] [ <a href="slides/technical_talk/bartel_upstream.pdf">Slides</a> ]<br>
<i>Maximilian Bartel</i><br>
<br>
MLIR is a key technology in modern ML compilers, but beginners often struggle with a common
question: How do I import my neural network into MLIR's upstream dialects? This talk provides a
practical introduction to model import workflows, covering TensorFlow Lite to TOSA, PyTorch to
MLIR via Torch-MLIR and torch.export, ONNX to MLIR using ONNX-MLIR and Torch-MLIR, and a brief
discussion on JAX. Designed for newcomers, this session will walk through concrete examples to help
lower the barrier to entry and clarify how ML models connect to MLIR's ecosystem.
</p>

<p>
TK Wave: A Symbolic Python/MLIR DSL and Compiler for High Performance Machine Learning [ Video ] [ <a href="slides/technical_talk/butygin_tk_wave.pdf">Slides</a> ]<br>
<i>Ivan Butygin</i><br>
<br>
We introduce Wave, a Python DSL and compiler for high performance machine learning.
Wave exposes a high level kernel language and user constraints to specify the distribution strategy
for the kernel while using the existing IREE/MLIR stack for the low-level optimizations and code
generation. The language and compiler make extensive use of symbolic data types to represent
tensor shapes and memory access patterns that make it easier to reason about the kernel.
</p>

<p>
llvmlite: A python gym for LLVM [ Video ] [ <a href="slides/technical_talk/singh_llvmlite.pdf">Slides</a> ]<br>
<i>Yashwant Singh</i><br>
<br>
LLVM has been used in countless innovative ways, and llvmlite is no exception. While it describes
itself as "a lightweight LLVM Python binding for writing JIT compilers," its potential extends far
beyond JIT compilation. This talk will explore how llvmlite empowers developers to i) Build an LLVM-
based compiler frontend in Python, ii) Experiment with LLVM optimizations and pipelines, and iii)
Dynamically execute IR code using LLVM's JIT engine. Whether you're an LLVM expert or just getting
started with compiler tooling, this session will demonstrate how Python can simplify LLVM
development, making rapid prototyping and experimentation more accessible than ever.
</p>

<p>
Making LoopAccessAnalysis more precise [ Video ] [ <a href="slides/technical_talk/ramachandra_loopaccessanalysis.pdf">Slides</a> ]<br>
<i>Ramkumar Ramachandra</i><br>
<br>
We talk about recent and ongoing work to make LoopAccessAnalysis more precise, leading to better
vectorization results.
</p>

<p>
C++ interoperability with memory-safe languages [ Video ] [ <a href="slides/technical_talk/horvath_cplusplus.pdf">Slides</a> ]<br>
<i>Gabor Horvath</i><br>
<br>
As the adoption of memory-safe languages increases and code written in memory-unsafe languages
remain widespread, polyglot projects—where multiple languages interact—are becoming more
common. This introduces new challenges around ensuring safe, efficient, and ergonomic
interoperability between these languages. This talk aims to spark a conversation about how Clang
can evolve to better facilitate interoperability with memory-safe languages.
</p>

<p>
Canonicalization in MLIR - Uniqueness and Equivalence [ Video ]<br>
<i>Javed Absar</i><br>
<br>
Canonicalization is a part of dialect, op and pass design in MLIR. It can be a much debated issue with
numerous valid concerns. In this talk, I will present :
(a) What is canonicalization and why it is important?
(b) Canonicalization in MLIR i.e. how it works; interesting examples etc.
(c) The different perspectives and concerns when it comes to canonicalization
</p>

<p>
Solving Compiler Puzzles: Debug Methods in MLIR [ Video ] [ <a href="slides/technical_talk/mcgirr_solving_compiler_puzzlespdf.pdf">Slides</a> ]<br>
<i>Christopher McGirr</i><br>
<br>
Debugging MLIR-based compilers can be challenging, from complex pass pipelines to subtle rewrite
pattern mismatches. This talk provides a deep-dive of the essential debugging tools and techniques,
helping novice developers efficiently diagnose and resolve issues. Topics include IR printing
mechanisms, useful mlir-opt arguments, reproducers, LLDB integration, and MLIR Reduce.
</p>

<p>
Function multi-versioning: compiler aided function specialization with runtime dispatch. [ Video ] [ <a href="slides/technical_talk/lamprineas_function_multi-versioning.pdf">Slides</a> ]<br>
<i>Alexandros Lamprineas</i><br><br>
We have implemented a new compiler feature for AArch64 and we need user feedback to further
develop/refine it. Function Multi Versioning (FMV) lets the compiler generate multiple function
versions and auto-dispatch between them. This is useful when running your code on CPUs which
implement optional instructions that are not guaranteed to be present on the target of compilation.
</p>

<p>
Bringing NVIDIA Blackwell support to LLVM and MLIR [ Video ]<br>
<i>Guray Ozen, Durgadoss Ramanathan, Pradeep Kumar</i><br><br>
NVIDIA's latest Blackwell architecture packs a great deal of new features for Generative AI and
accelerated computing towards Tensor Compute. Platform support for these features is being
actively added in upstream LLVM and MLIR projects. This comes in various forms mainly in the form
of intrinsics, newer type additions to the APFloat subsystem, as well as exposing them in the
NVGPU/NVVM dialects of MLIR. In the first-part of the talk, we will discuss the challenges we faced in
modelling these features as intrinsics, evaluated alternatives, as well as the lessons learnt in
implementing them in the NVPTX backend as well as in the NVVM Dialect. The second-part of the
talk aims to provide a hands-on tutorial on writing sample kernels using NVDSL in python.
</p>

<p>
Pass Plugins: Past, Present and Future [ Video ] [ <a href="slides/technical_talk/graenitz_pass_plugins.pdf">Slides</a> ]<br>
<i>Stefan Gränitz</i><br><br>
LLVM has been driving the diversification of compiler-based tools successfully for many years. And
we still keep implementing everything in the monorepo upstream. This pulls more and more domain-
specific features into general purpose toolchains. The advent of the RealtimeSanitizer in Clang 20
illustrates this very well. Pass plugins allow 3rd-party additions in both, LLVM and MLIR already
without further bloat in our codebase. But so far their capabilities are limited.
This talk will give an overview of the history and present state of pass plugins. Based on that it
proposes an initial set of changes that would allow domain-specific extensions to utilize the plugin
interface for sanitizer-like tasks. It's meant as a kick-off to bring interested parties to a round table
and discuss how a version 2 of the plugin interface could look like.
</p>

<p>
Parallelizing the LLVM Pipeline with MCLink [ Video ] [ <a href="slides/technical_talk/chen_parallelizing.pdf">Slides</a> ]<br>
<i>Weiwei Chen</i><br><br>
Like many programming languages and compiler systems built on top of the MLIR framework with
LLVM as the backend, the LLVM pipeline is the bottleneck for compilation time for the Mojo compiler.
In this talk, we will discuss our approach on LLVM pipeline parallelization and a unique component
called MCLink which helps to significantly reduce the time spent in LLVM of overall Mojo compilation
time with no modifications in the generated code.
</p>

<p>
Devise Loop Distribution with Scalar Expansion for Enhancing Auto-Vectorization in LLVM [ Video ] [ <a href="slides/technical_talk/lai_loop_distribution.pdf">Slides</a> ]<br>
<i>Hung-Ming Lai, Jenq-Kuen Lee</i><br>
<br>
In this work, we present a novel approach that integrates Data Dependence Graph (DDG) and Scalar
Expansion techniques into LLVM's LoopDistribute pass to enhance auto-vectorization optimization.
We identify key limitations in the current LoopDistribution pass and devise a DDG-based partitioning
algorithm with scalar expansion technique to enable more precise loop distribution and better
vectorization opportunities. The talks will cover both the algorithm for the proposed method and a
compile-time regression report for our initial implementation on benchmarks.
</p>

<p>
How to trust your peephole rewrites: automatically verifying them for arbitrary width! [ Video ] [ <a href="slides/technical_talk/bhat_peephole.pdf">Slides</a> ]<br>
<i>Siddharth Bhat</i><br>
<br>
We develop algorithms to prove peephole optimzations correct in a bitwidth-generic fashion, and
apply it to hacker's delight, rewrites mined from InstCombine, and challenging problems from
program deobfuscation. We explain the core ideas of the algorithm, as well as the implementation,
evaluation, and proofs which we performed in the Lean proof assistant. Finally, we demo the
interface to the end-user, which provides a command (bv_automata) to prove theorems about
bitvector rewrites that are universally quantified over the bitwidth. We hope to use our algorithm to
simplify the many thousands of lines of proof in the Lean bitvector standard library, and more
broadly, hope to provide effective proof automation for bitvector predicates that quantify over bitwidth.
</p>

<p>
Accidental Dataflow Analysis: Extending the RISC-V VL Optimizer [ Video ] [ <a href="slides/technical_talk/lau_accidental_dataflow.pdf">Slides</a> ]<br>
<i>Luke Lau</i><br>
<br>
A tour of some recent work on the RISC-V backend, motivated by the ongoing effort to implement
VL tail folding for the vector extension. We showcase an engineering-first approach to a classical
compiler problem: Looking at how to identify areas of code generation to improve, how some
incremental changes to the VL optimizer pass led to a form of dataflow analysis, and how we can
guarantee some properties by looking at the underpinning mathematical theory.
</p>

<p>
LLVM IR -- Past, Present and Future [ Video ] [ <a href="slides/technical_talk/popov_llvm_ir.pdf">Slides</a> ]<br>
<i>Nikita Popov</i><br>
<br>
LLVM IR (intermediate representation) is the foundation that LLVM is built on. It has stood the test of
time, with many fundamentals remaining unchanged since its inception. At the same time, LLVM IR is
continuously evolving to enable new optimizations and keep up with changing requirements. This
talk will cover some high-level design considerations, past changes to IR design, as well as changes
planned for the future.
</p>

<p>
Faster Compilation — Improvements in LLVM 20 and Beyond [ Video ]<br>
<i>Alexis Engelke</i><br>
<br>
Over the last two release cycles, LLVM's back-end has seen substantial performance improvements
of up to 18% (-O0 x86-64). In this talk, we will describe how these improvements were achieved,
summarize lessons learned from finding and implementing these optimizations, and outline paths
and ideas for further compile-time reductions in the future.
</p>

<p>
Bridging LLVM and SPIR-V for Heterogeneous Computing [ Video ] [ <a href="slides/technical_talk/levytskyy_bridging.pdf">Slides</a> ]<br>
<i>Vyacheslav Levytskyy, Michal Paszkowski</i><br>
<br>
This presentation showcases the key changes to the SPIR-V backend that have solidified its position
as a robust, vendor-agnostic alternative to the Khronos LLVM/SPIR-V Translator. We explore recent
feature enhancements, translation time optimizations, and quality assurance processes that enabled
seamless integration with other projects for heterogeneous computing workflows, including GPU
programming for neural networks. Emphasis is placed on bridging the requirements of the SPIR-V
standard, relevant execution environment specifications, and LLVM's code-lowering infrastructure.
Key topics include technical solutions for the SPIR-V type system, module vs. function scope
handling, and managing the logical layout of modules—factors essential to both performance and
maintainability. We also discuss our use of TableGen-based register classes, improvements to type
deduction passes, and how these strategies ensure formal correctness while expanding support for
SPIR-V extensions, built-ins, and intrinsics. Finally, the talk covers insights into introducing the
backend into the DPC++ compiler and OpenAI Triton backend for Intel GPUs, along with details on the
broader quality assurance and integration efforts that benefit both compute-centric and graphical
use cases alike.
</p>

<p>
Instrumentor: Easily Customizable Code Instrumentation [ Video ] [ <a href="slides/technical_talk/sala_instrumentor.pdf">Slides</a> ]<br>
<i>Johannes Doerfert, Kevin Sala</i><br>
<br>
The Instrumentor is a new LLVM pass that allows instrumenting code in a simple and customizable
way. It can be used from within LLVM as any other pass, or from any frontend via a descriptive JSON
file. The Instrumentor provides a unified and simple method for instrumenting code, reducing
maintainability costs and code replication, as well as paving the path for future instrumentation-
based tools. Our technical talk will cover the functionalities of the Instrumentor, which will be helpful
for compiler, runtime and tool developers, and we will show its versatility through several use cases.
</p>

<p>
Advances in Function Merging and Symbolication [ Video ] [ <a href="slides/technical_talk/lee_function_merging.pdf">Slides</a> ]<br>
<i>Alex Borcan, Kyungwoo Lee</i><br>
<br>
Optimizing code size is crucial for mobile applications, and function merging is a key technique to
achieve this by consolidating identical or similar functions. Recent advancements in global function
merging and identical code folding (ICF) at link time have resulted in significant size reductions, with
a 3% reduction on top of the state-of-the-art global outliner and affecting 15% of total functions.
Additionally, a new safe_thunks mode has been introduced to improve binary size reduction without
compromising runtime safety, achieving an additional 0.45% size savings over regular safe ICF.
However, function merging poses challenges for symbolication, which have been addressed through
enhancements such as a new DWARF attribute and extended GSYM format support, laying the
groundwork for more accurate symbolication in optimized binaries.
</p>

<p><b>Tutorials:</b></p>

<p>
Adopting -fbounds-safety in practice [ Video ] [ <a href="slides/tutorial/olsonn-stefaniski_fbounds.pdf">Slides</a> ]<br>
<i>Henrik Olsson, Patryk Stefanski</i><br><br>
-fbounds-safety is a C extension in Clang for enforcing bounds safety in C, developed and deployed
internally at Apple. The implementation is currently in the process of being upstreamed to mainline
LLVM, and a preview is now available to try out in a fork of LLVM. While previously outline in a talk
at EuroLLVM 2023, this time we will cover the practical details of -fbounds-safety adoption.
</p>

<p>
How to reduce an llvm bug [ Video ] [ <a href="slides/tutorial/arsenault_reduce.pdf">Slides</a> ]<br>
<i>Matthew Arsenault</i><br><br>
In this talk, I will provide a walkthrough of how to reduce common
types of bugs (primarily crashes) in the middle end and backend. This
will serve as an introduction to and documentation of how to use
llvm-reduce. I will discuss common roadblocks and bugs you may need to
workaround (some of which should probably be fixed). I will also argue
that it is long overdue to delete bugpoint and discuss how to add new
reduction passes if there is time.
</p>

<p>
An Introduction to Tensor Tiling in MLIR [ Video ]<br>
<i>Kunwar Grover, Mahesh Ravishankar</i><br><br>
This talk will introduce the audience to TileAndFuse, an algorithm in upstream MLIR which allows
tiling tensor operations and fusing these tiled tensor operations. The talk will cover how the
algorithm works, how users can use it in their compiler and different tiling and distribution pipelines
that can be built using it.
</p>

<p><b>Lightning Talks:</b></p>

<p>
What is LLDB-DAP? [ Video ] [ <a href="slides/lightning_talk/devlieghere_lldb-dap.pdf">Slides</a> ]<br>
<i>Jonas Devlieghere</i><br>
<br>
lldb-dap is a utility that allows LLDB to work with editors and IDEs that support the Debug Adapter Protocol (DAP), such as
Visual Studio Code. It builds on LLDB's stable API and uses a standardized protocol to act as a bridge between LLDB and
other developer tools. It is part of the Xcode developer tools and the open source Swift toolchain. It is also the name of the
official VS Code extension, which is available in the Marketplace. We'll talk about the Debugger Adapter Protocol, how we
support it in LLDB and where the line is between the IDE-agnostic tool and the VSCode extension.
</p>

<p>
sd-visualiser: Interactive graph visualisation for SSA-based IRs [ Video ] [ <a href="slides/lightning_talk/rice_sd-visualiser.pdf">Slides</a> ]<br>
<i>Alex Rice</i><br>
<br>
We present "sd-visualiser", an interactive graph visualisation program. It is specialised for drawing constructions common in
LLVM and MLIR, such as regions, blocks, nodes with multiple ordered inputs and outputs, and SSA-values with multiple
uses. We will demo the tool, and show off some of its interactive features.
</p>

<p>
Beyond Pattern-based Optimization: What Can LLM Reshape Auto-vectorization? [ Video ] [ <a href="slides/lightning_talk/cheng_beyond_pattern.pdf">Slides</a> ]<br>
<i>Long Cheng</i><br>
<br>
Our talk, "Beyond Pattern-based Optimization: What Can LLM Reshape Auto-vectorization?", presents a novel LLM-driven
framework integrated into LLVM-based compilers. By combining the semantic reasoning capbility of LLM(Deepseek V3) with
the precision of traditional LLVM-based compilers, we tackle complex vectorization scenarios which is generally hard to be
done for naive LLVM-based compilers. We'll share results from TSVC-2 HPC and Skia benchmarks, demonstrating
significant performance improvements (1.42× to 1.91×) on SVE/Neon for Arm CPUs. Learn how this approach reshapes
auto-vectorization and discover future directions for LLM-native compiler optimization.
</p>

<p>
Why add an IR Reader to the llvm-debuginfo-analyzer tool? [ Video ] [ <a href="slides/lightning_talk/alberto_enciso_ir_reader.pdf">Slides</a> ]<br>
<i>Carlos Alberto Enciso</i><br>
<br>
The llvm-debuginfo-analyzer is a tool developed by Sony, as part of the open-source LLVM project. We have added support
for the LLVM IR format. This talk will cover the benefits to allow compare IRs at different stages and determine any specific
changes.
</p>

<p>
To be OR NOT to be [ Video ] [ <a href="slides/lightning_talk/fusik_to_be.pdf">Slides</a> ]<br>
<i>Piotr Fusik</i><br>
<br>
RISC-V has inverted bitwise operations such as "or not". I will present a few scenarios where they are useful and how I
implemented them in LLVM.
</p>

<p>
Accidentally quadratic in compiler-rt/asan [ Video ] [ <a href="slides/lightning_talk/pianykh_quadratic.pdf">Slides</a> ]<br>
<i>Artem Pianykh</i><br>
<br>
You build your binary with ASan, you run it... and nothing happens for 10 seconds. Without ASan the binary starts instantly.
This talk will discuss how a bad asymptotic in the ODR checker's runtime code turned into a practical performance
bottleneck, the fix to this problem, and the importance of tight upper bounds.
</p>

<p>
Dialects as a Dialect: Bringing native C++ registration to IRDL [ Video ] [ <a href="slides/lightning_talk/ho_dialects.pdf">Slides</a> ]<br>
<i>Ivan Ho</i><br>
<br>
IRDL allows to define dialects in MLIR in a declarative and easy to analyse fashion. While this feature set was useful on its
own, IRDL-defined dialects were not tightly integrated into MLIR: it was notably impossible to realistically use C++ patterns
on them, or use dialect conversion with them. We present how we created a new MLIR tool capable of generating C++
definitions for dialects, just like ODS with TableGen. With our tool, IRDL-defined dialects are now tightly integrated into MLIR
and indistinguishable from ODS dialects from a user's perspective. We also present how we wish to improve the code
template rendering tooling in LLVM.
</p>

<p>
Autocheck – Clang-Based Checker for Automotive: Status and Issues [ Video ] [ <a href="slides/lightning_talk/todorovic_autocheck.pdf">Slides</a> ]<br>
<i>Djordje Todorovic</i><br>
<br>
Autocheck is a clang-based source code analysis tool designed to enforce compliance with the automotive standards,
ensuring that critical automotive software adheres to strict safety and quality guidelines. In this talk, I will present the current
status of Autocheck, discussing its implementation using the clang API, the challenges we have encountered—particularly
around open-sourcing due to licensing and approval hurdles—and our roadmap for supporting both the current and new
versions of the automotive standards, usage of AI, and more.
</p>

<p>
LLDB Statusline [ Video ] [ <a href="slides/lightning_talk/devlieghere_lldb_statusline.pdf">Slides</a> ]<br>
<i>Jonas Devlieghere</i><br>
<br>
Motivated by a better place to show progress events and a way to display the current state of the debugger, I extended
command-line LLDB with a statusline. This dedicated area at the bottom of the screen shows things like the current target,
the stop reason, and progress updates. The statusline can be customized using LLDB's format strings. I'll talk a little bit about
the motivation, the implementation, and how to configure it.
</p>

<p>
Defining and verifying MLIR operations with constraints [ Video ] [ <a href="slides/lightning_talk/rice_constraints.pdf">Slides</a> ]<br>
<i>Alex Rice</i><br>
<br>
This talk describes work in progress on a new constraint-based system for defining MLIR operations, which can be used to
declaritely specify complex verification procedures, as well as providing inference of operation fields used when defining
custom syntax of MLIR operations.
</p>

<p><b>Quick Talks:</b></p>

<p>
Leveraging "nsw" in Flang's LLVM IR Generation for Vectorization [ Video ] [ <a href="slides/quick_talk/minato_nsw.pdf">Slides</a> ]<br>
<i>Yusuke Minato</i><br><br>
Flang is the Fortran frontend in the LLVM project. Its quality and performance have been improving, so that its driver has
been renamed from "flang-new" to "flang" since LLVM 20. With respect to optimizations, loop vectorization plays an important
role because it can reduce the number of operations in a loop by half or more. This talk focuses on Flang's capability of
vectorization in the backend and our work on "nsw" to improve the capability. As a result of our work, loop vectorization for
Fortran has been enhanced by introducing several options related to integer overflow into Flang.
</p>

<p>
Leveraging LLVM for Instruction Cache Prefetching on Simple Architectures [ Video ] [ <a href="slides/quick_talk/avraham_prefetching.pdf">Slides</a> ]<br>
<i>Oriel Avraham</i><br>
<br>
This talk explores the addition of a lightweight, non-blocking instruction cache prefetching mechanism tailored for simple
hardware architectures without built-in I$ optimization components. We will discuss how the LLVM framework can be used to
identify strategical points for prefetch insertion through static analysis
</p>

<p>
#embed in clang: one directive to embed them all [ Video ] [ <a href="slides/quick_talk/podchishchaeva_embed.pdf">Slides</a> ]<br>
<i>Lukas Sommer</i><br>
<br>
The C23 standard defines the #embed directive – a fast, simple, tooling-friendly, cross-platform standardized way to include
binary data into an application. For 40+ years of C and C++ implementations every compiler, every linker, every platform had
its own little bespoke way of putting data into your executable. Since 2024 with C23 we now have #embed in clang: just one
directive to (rule) embed them all. This talk will present the language feature design, feature status in clang, clang
implementation details, and challenges faced during the implementation.
</p>

<p>
LLVM_ENABLE_RUNTIMES=flang-rt [ Video ] [ <a href="slides/quick_talk/kruse_flang-rt.pdf">Slides</a> ]<br>
<i>Michael Kruse</i><br>
<br>
Flang's runtime library was changed from being compiled as part of Flang itself, to using LLVM's mechanism for runtime
libraries. On this occasion this talk is about the motivation behind this change, design choices, the implications for users,
experiences of the conversion, the purpose of runtime libraries, comparison to Clang's runtime libraries, and the differences
between LLVM_ENABLE_PROJECTS and LLVM_ENABLE_RUNTIMES.
</p>

<p>
LLDB support for Propeller optimized code [ Video ] [ <a href="slides/quick_talk/labath_propeller.pdf">Slides</a> ]<br>
<i>Pavel Labath</i><br>
<br>
Propeller optimization boosts binary performance by up to 20%, but creates challenges for LLDB due to non-continuous
functions. This talk unveils how LLDB was adapted to handle these complexities and explains how to avoid common pitfalls
when writing new LLDB code.
</p>

<p>
1:N Dialect Conversion in MLIR [ Video ] [ <a href="slides/quick_talk/springer_dialect_conversion.pdf">Slides</a> ]<br>
<i>Matthias Springer</i><br>
<br>
The dialect conversion framework, one of the core pattern drivers in MLIR, has recently been extended with 1:N support:
replacing one SSA value with multiple other SSA values. This talk illustrates how to use the new infrastructure and migrate
existing passes that are currently relying on workarounds
</p>

<p>
Enhancing Tile & Fuse Transformation in MLIR with a Planning Interface [ Video ] [ <a href="slides/quick_talk/cohen_planning_interface.pdf">Slides</a> ]<br>
<i>Aviad Cohen</i><br>
<br>
The MLIR project provides a Tile & Fuse transformation to enhance memory locality by breaking down computations into
smaller tiles and merging tiled loops. While the transformation utilities exist, determining optimal tiling and fusion decisions is
challenging due to the lack of readily available iteration domain mapping information. This talk proposes a new interface to
expose this critical mapping independent of the transformation process, enabling more informed and flexible tiling and fusion
strategies. By providing a common solution, this interface aims to benefit both in-tree and out-of-tree dialects, addressing
challenges faced by downstream projects and improving the broader MLIR ecosystem.
</p>

<p>
LTO/BOLT Optimised Clang/LLD AArch64 toolchain [ Video ] [ <a href="slides/quick_talk/yakubova_lto_bolt.pdf">Slides</a> ]<br>
<i>Elvina Yakubova</i><br>
<br>
In this talk, we present our work on building a faster AArch64 Clang compiler by using an advanced LTO-PGO-BOLT build.
We'll show that using the default settings leads to regressions in some applications due to its training on C++ codebases. To
address this issue, efforts are made to diversify the training phase and merge profiles from applications with different
codebases to develop a LTO-PGO-BOLT-optimized compiler that achieves higher performance across a wider range of
applications.
</p>

<p>
MLIR Tensor Compiler Charter Update [ Video ] [ <a href="slides/quick_talk/morel_mlir_tensor.pdf">Slides</a> ]<br>
<i>Rolf Morel</i><br>
<br>
This will be an update on the current efforts to consolidate the MLIR charter via the recently formed design group. In the two
months before EuroLLVM, we'll collect rationale, design and implementation documents, review contents and propose
changes and reach a state where we'll be in a position to start making more assertive suggestions based on the community's
feedback on current progress. This effort will continue upstream, in the open, but we recognize that the volume and intensity
of discussions can be daunting, so we plan to present a summary of the current state and potential futures, which will lead
into a round table for discussions, and follow-up forum threads to finally reach back the rest of the community.
</p>

<p>
Accurate Runtime Performance Estimation for Predictably Training ML Guided Register Eviction Policies [ Video ] [ <a href="slides/quick_talk/grossman_accurate_runtime.pdf">Slides</a> ]<br>
<i>Aiden Grossman</i><br>
<br>
Within this talk, we describe how we trained a machine-learned register allocation heuristic using a new trace-based runtime
estimation methodology. We outline how our new performance estimation system works, our overall training process, and our
results, where we were able to achieve performance gains of around 1% on some server binaries.
</p>

<p>
The New Premerge System [ Video ] [ <a href="slides/quick_talk/grossman_premerge_system.pdf">Slides</a> ]<br>
<i>Lucile Rose Nihlen, Aiden Grossman</i><br>
<br>
Here we talk through the redesigned premerge system. We show a demo of the system in action from the contributor
perspective, talk through the public analytics to understand system performance and reliability, explain the SLO and on-call
process, provide a technical overview of the system, and answer any questions the audience might have.
</p>

<p>
Measuring the health of the LLVM community [ Video ] [ <a href="slides/quick_talk/bennett_community_health.pdf">Slides</a> ]<br>
<i>Jeremy Bennett</i><br>
<br>
In this short talk, I look at how data mining of git activity and mailing lists can give insight to the health for a community
project. The talk offers no prescriptions, its purpose is to share techniques that may be useful to the community.
</p>

<p>
Lessons learned from leveling up RISC-V LLVM testing [ Video ] [ <a href="slides/quick_talk/bradbury_lessons_learned.pdf">Slides</a> ]<br>
<i>Alex Bradbury</i><br>
<br>
Testing is essential to ensuring the quality of LLVM's releases and maintaining its development velocity. LLVM has built an
extensive collection of CI and testing infrastructure over the years, but it can be challenging to stand up builders that provide
a reasonable cycle time for scenarios such as testing a backend of target configuration where high performance hardware
isn't (yet) readily available. This talk describes work done to improve the situation for RISC-V, including extending support for
qemu and cross-compilation scenarios, improvements to documentation and the ability to test buildbot configurations locally,
balancing available compute resource vs configuration coverage vs test cycle time, and the path to providing feedback
beyond functional testing (e.g. code size, performance).
</p>

<p>
Small Changes, Big Impact: GitHub Workflows for the LLVM Project [ Video ] [ <a href="slides/quick_talk/spickett_github_workflows.pdf">Slides</a> ]<br>
<i>David Spickett</i><br>
<br>
LLVM contributors benefit from GitHub workflows every day, but did you know that if you want to write one of your own, all
you need is a GitHub account? Find out how to get started, iterate and test, then finally submit your workflow to LLVM where
100s of developers can benefit from it.
</p>

<p><b>Student Technical Talks:</b></p>

<p>
Clang Static Analyzer: Supporting Multithreaded Code [ Video ] [ <a href="slides/student_technical_talk/nudelman_clang_static.pdf">Slides</a> ]<br>
<i>Isaac Nudelman</i><br>
Writing multithreaded code is notoriously difficult. Compounding this, static analysis is not particularly
effective, as most analyzers (including Clang) are limited to evaluating a single thread of symbolic
execution. This talk will describe changes to the Clang Static Analyzer to support analysis across
threads, the challenges with the implementation, and the resulting improvement in analysis quality for
multithreaded codebases. In particular, we will show multiple bugs that can now be detected using static
analysis.
</p>

<p>
Integrating XRay into the HPC Tool Ecosystem [ Video ] [ <a href="slides/student_technical_talk/kreutzer_integrating_xray.pdf">Slides</a> ]<br>
<i>Sebastian Kreutzer</i><br>
<br>
XRay, Clang's dynamic function tracing system, offers runtime-adaptable instrumentation with minimal overhead.
However, its adoption in HPC has been limited due to missing support for shared libraries (DSOs) and insufficient
integration with parallel programming models like MPI and OpenMP. This talk presents our efforts to bridge these
gaps, including our recently upstreamed extension for DSO instrumentation and the integration of XRay into
established performance tools such as Score-P, TALP, and Extrae. Additionally, we present ideas for future work
to enhance XRay's filtering mechanisms and instrumentation flexibility.
</p>

<p>
Automatic LLVM compiler backend generation with OpenVADL [ Video ] [ <a href="slides/student_technical_talk/per_openvadl.pdf">Slides</a> ]<br>
<i>Kevin Per</i><br>
<br>
The Vienna Architecture Description Language (VADL) is a processor description language for rapid design space
exploration. OpenVADL is the open source implementation of VADL. One of the generated artifacts is an LLVM
compiler backend. This talk provides an overview of how an automatic compiler backend generator was
implemented and discusses the problems and limitations it faces. More details are described in an article available
at https://arxiv.org/pdf/2402.09087
</p>

<p>
Pattern Matching, Transform and Code Replacement using LLVM's Polly library [ Video ] [ <a href="slides/student_technical_talk/huber_pattern_matching.pdf">Slides</a> ]<br>
<i>Benedikt Huber</i><br>
<br>
Multidimensional Match, Transform and Replace (MMTR), is an extension to LLVM's Polly library, capable of
matching, transforming and replacing nested loops using the polyhedral model. According to a user defined, target
specific pattern, MMTR identifies nested loops that are semantically equivalent to an optimized target
implementation. On a successful match, it transforms the nested loop in such a way that it can be replaced by a call
to this optimized target implementation.
</p>

<p>
How to Write a Scalable Compiler for an Error-Prone Quantum Computer [ Video ]<br>
<i>Kim Worrall</i><br>
<br>
Quantum computers have a problem - they are susceptible to errors which can destroy the entire computation.
Error correction will make quantum computers feasible, but the architecture and software needed is multi-level,
distributed, data intensive, time critical, and crucially not yet integrated into a compilation pipeline. This talk
presents our effort to bring together the disparate parts of the quantum ecosystem into an error-correction aware,
MLIR compatible framework. In particular, we emphasise how lessons from the MLIR and LLVM community are
crucial to the frameworks development, and invite the audience to get involved with quantum computing.
</p>

<p>
Optimizing FDTD Solvers for Electromagnetics Using MLIR Across Multiple Hardware Platforms [ Video ] [ <a href="slides/student_technical_talk/he_optimizing_fdtd.pdf">Slides</a> ]<br>
<i>Yifei He</i><br>
<br>
The Finite-Difference Time-Domain (FDTD) method is essential for computational electromagnetics but is
computationally intensive. This talk explores how MLIR optimizations—loop tiling, fusion, and vectorization—
significantly accelerate FDTD simulations. We showcase MLIR's potential for efficient, portable FDTD solvers
across Intel, AMD, ARM CPUs, and GPUs.
</p>

<p><b>Posters:</b></p>

<p>
LLVM Support for Sub-FP8 Quantization with RISC-V Extensions for Machine Learning Models [ <a href="slides/poster/chapman_sub_fp8.pdf">Slides</a> ]<br>
<i>Kathryn Chapman, Fu-Jian Shen</i><br>
<br>
Deep learning computations require substantial computational power, storage, and data transfer bandwidth. To
enhance efficiency, model quantization has become essential, driving the evolution of data formats from 32-bit and
16-bit to 8-bit, 6-bit, and 4-bit in both integer and floating-point representations. Previously, at the RISC-V
Summit, North America, 2024, we proposed the Sub-FP8 extension for RISC-V, a novel approach to low-precision
floating-point computation. In this work, we further provide Sub-FP8 support in the LLVM backend, along with
C/C++ intrinsics to facilitate its integration into machine learning workloads. In addition, a reference design of
Sub-FP8 is in the on-going work to integrate with CVA6 and FPnew core from open hardware. In our reference
design, we also look at the issues to integrate Sub-FP8 with risc-v vector and matrix extensions, respectively.
Experiments and simulations with Toolkits such as Spike and Gem5 will be also presented.
</p>

<p>
Towards Multi-Level Arithmetic Optimizations [ <a href="slides/poster/ledoux_optimizations.pdf">Slides</a> ]<br>
<i>Louis Ledoux, Florent de Dinechin, Luc Forget</i><br>
<br>
Numerical code is usually conceived using real numbers. However, programming languages only provide
constructs operating at the lower abstraction level of machine encoding arithmetic. This work introduces an MLIR
dialect for representing computations on real numbers at a high abstraction level. This enables more opportunities
of arithmetic optimizations than those supported by current compilers. Such optimisations are particularly relevant
when compiling a high-level mathematical description to application-specific hardware, for instance in signal
processing and AI acceleration.
</p>

<p>
CuSan: a data race detector for CUDA based on ThreadSanitizer [ <a href="slides/poster/hueck_cusan.pdf">Slides</a> ]<br>
<i>Alexander Hück</i><br>
<br>
CuSan is a tool for detecting data races between (asynchronous) CUDA calls and the host. To achieve this, we
analyze and instrument CUDA API usage in the target code during compilation with Clang/LLVM to track
CUDA-specific concurrency, memory accesses and synchronization semantics. Our runtime then exposes this
information to ThreadSanitizer for final data race analysis.
</p>

<p>
SonicMachine: Scalable Architecture Description using MLIR [ <a href="slides/poster/khan_sonicmachine.pdf">Slides</a> ]<br>
<i>Daniyal Khan</i><br>
<br>
SonicMachine is a novel MLIR dialect designed to efficiently represent complex, large-scale machine learning
architectures, addressing the challenges of modeling hierarchical structures and data movement in modern
accelerators. By leveraging MLIR's shape system, SonicMachine enables explicit representation of
interconnections and performance attributes through operations like slice, concat, and broadcast, along with builder
functions and templates for scalable descriptions. This work demonstrates how compiler infrastructure can
facilitate expressive, hierarchical hardware modeling, providing a foundation for analysis, optimization, and
efficient system design.
</p>

<p>
Coroutines, reinforcement learning environments, typechecking, MLIR: tying them together. [ <a href="slides/poster/fioravanti_coroutines.pdf">Slides</a> ]<br>
<i>Massimo Fiorovanti</i><br>
<br>
While machine learning tools become simpler by the day, developing robust environments for those tools to
operate in remains an open challenge. Rulebook is an MLIR and coroutine-based DSL aimed at building
environments and simplifying their interoperability. This talk describes the issues found at the boundaries between
machine learning agents and machine learning environments from a programming language perspective, how
Rulebook solves them, what challenges prevent other languages from adopting the same constructs, how the
language leverages LLVM and MLIR to achieve its purpose, and various tips and tricks learned from
implementing co-routines on top of MLIR. 
</p>

<p>
Code-generation of highly efficient finite element operations using the MLIR compiler infrastructure [ <a href="slides/poster/erasmie-jones_ecode.pdf">Slides</a> ]<br>
<i>Edward Erasmie-Jones</i><br>
<br>
In this poster, we present NektarIR, a work-in-progress high-level intermediate representation of high-order finite
element operations, built using the MLIR compiler infrastructure. Our goal is to address the software
fragmentation that arises in developing highly efficient finite element kernels for heterogeneous hardware by
enabling the generation of hardware-specific JIT-compiled kernels through both MLIR and LLVM. We
demonstrate the initial stages in the development of our MLIR dialect and the performance of JIT-compiled finite
kernels, tested as a back-end for the Nektar++ spectral/hp element framework.
</p>

<div class="www_sectiontitle" id="coc">Code of Conduct</div>
<p>The LLVM Foundation is dedicated to providing an inclusive and safe
experience for everyone. We do not tolerate harassment of participants in any
form. By registering for this event, we expect you to have read and agree to
the <a href="http://llvm.org/docs/CodeOfConduct.html">LLVM Code of Conduct</a>.
</p>

<div class="www_sectiontitle" id="contact">Contact</div>
<p>To contact the organizer,
<a href="mailto:events@llvm.org"> email events@llvm.org</a>
</p>

</div>
</td>
</tr></table>
</div>
<!-- *********************************************************************** -->

<!--#include virtual="sponsors.incl" -->

<hr>

<!--#include virtual="../../footer.incl" -->
