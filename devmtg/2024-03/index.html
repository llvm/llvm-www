<!--#include virtual="../../header.incl" -->

<div class="www_sectiontitle">Eighth LLVM Performance Workshop at CGO</div>

<ul>
  <li><b>What:</b> Eighth LLVM Performance Workshop at CGO</li>
  <li><b>When:</b> March 2nd, 2024 (Saturday)</li>
  <li><b>Where:</b> <a href="https://conf.researchr.org/venue/cgo-2024/cgo-2024-venue" target="_blank">Venue The Exchange, 150 Morrison St, EH3 8EE, Edinburgh, United Kingdom) </a> [In person]</li>
  <li><b>Proposals should be submitted to:</b> <a href="https://easychair.org/conferences/?conf=llvmcgo2024
        ">Easychair Submission </a></li>
  <li><b>The deadline for receiving submissions is:</b> : January 25th, 2024</li>
  <li><b>Speakers will be notified of acceptance or rejection by:</b> February 1st, 2024</li>
  li>Note: Travel grants are available upon request. Please reach out to the program committee if you need travel grant for the workshop.</li>
</ul>

<p>
  The Eighth LLVM Performance Workshop will be held at
  (<a href="https://conf.researchr.org/track/cgo-2024/cgo-2024-workshops-and-tutorials">CGO 2024</a>). The
  workshop is co-located with CC, HPCA, and PPoPP. If you are interested
  in attending the workshop, please register at the
  (<a href="https://conf.researchr.org/home/cgo-2024">CGO website</a>). The LLVM workshop
  at CGO will be in-person.
</p>

<p>
  Program Committee:
<ul>
  <li>Johannes Doerfert (jdoerfert at llnl.gov)</li>
  <li>Aditya (hiraditya at msn.com)</li>
  <li>Jose M Monsalve Diaz (jmonsalvediaz at anl.gov)</li>
  <li>Shilei Tian (i at tianshilei.me)</li>
  <li>Rafael A Herrera Guaitero (rafaelhg at udel.edu)</li>
</ul>
</p>

<div class="www_sectiontitle" id="workshop-schedule">Schedule [WIP] </div>

<table width="100%" border="1">
  <tbody>
    <tr style="font-weight: bold">
      <td style="min-width: 160px;">
        <p>Time (EDT)</p>
      </td>
      <td>
        <p>Speaker</p>
      </td>
      <td>
        <p>Title</p>
      </td>
      <td>
        <p>Topic</p>
      </td>
    </tr>
    <tr>
      <td>
        <p>8:00 - 8:10 (10 min)</p>
      </td>
      <td>
        <p>
          <a href="https://www.linkedin.com/in/josemonsalve2/">Jose M Monsalve Diaz</a><br />
          <a href="https://www.linkedin.com/in/shiltian/">Shilei Tian</a><br />
          <a href="https://www.linkedin.com/in/johannes-doerfert-3a0770a2">Johannes Doerfert</a><br />
          <a href="https://twitter.com/_hiraditya_">Aditya</a><br />
          <a href="https://www.linkedin.com/in/randres-herrera/">Rafael A Herrera Guaitero</a>
        </p>
      </td>
      <td>
        <p>Opening Remarks</p>
      </td>
      <td>
        <p>Welcome and Introduction</p>
      </td>
    </tr>
    <!-- Talk 1 -->
    <tr>
      <td>
        <p>8:10 - 8:35 (25 min)</p>
      </td>
      <td>
        <p>
          Shivam Kunwar<br />
        </p>
      </td>
      <td>
        <p>
          <a href="#talk1">Map LLVM Values to corresponding source-level expression</a>
          <!-- <br/><span style="font-family: monospace;">[<a href="slides/RL4ReAl.pdf">slides</a>]</span> -->
        </p>
      </td>
      <td>
        <p>	
          LLVM<br />
          C++<br />
          Loop Vectorization<br />
          Debug Info<br /></p>
      </td>
    </tr>
    <!-- Talk 2 -->
    <tr>
      <td>
        <p>8:35 - 9:00 (25 min)</p>
      </td>
      <td>
        <p>
          Tomaz Canabrava<br />
        </p>
      </td>
      <td>
        <p>
          <a href="#talk2">Using LLVM to inspect, and fix, the Physical Structure of a Large Scale Software - The Codevis Project</a>
          <!-- <br/><span style="font-family: monospace;">[<a href="slides/RL4ReAl.pdf">slides</a>]</span> -->
        </p>
      </td>
      <td>
        <p>
          Software Visualization<br />
          Large Scale<br />
          LLVM<br />
          Clang<br />
          Flang<br />
        </p>
      </td>
    </tr>
    <!-- Talk 3 -->
    <tr>
      <td>
        <p>9:00 - 9:25 (25 min)</p>
      </td>
      <td>
        <p>
          Amir Ayupov<br />
        </p>
      </td>
      <td>
        <p>
          <a href="#talk3">Practical Use of BOLT</a>
          <!-- <br/><span style="font-family: monospace;">[<a href="slides/RL4ReAl.pdf">slides</a>]</span> -->
        </p>
      </td>
      <td>
        <p>
          LLVM<br />
          BOLT<br />
          PGO<br />
          Profile-guided optimizations<br />
          Profiling<br />
        </p>
      </td>
    </tr>
    <!-- Talk 4 -->
    <tr>
      <td>
        <p>9:25 - 9:50 (25 min)</p>
      </td>
      <td>
        <p>
          Venkatakeerthy S,<br />
          Siddharth Jain,<br />
          Umesh Kalvakuntla,<br />
          Pranav Sai Gorantla,<br />
          Rajiv Shailesh Chitale,<br />
          Eugene Brevdo,<br />
          Albert Cohen,<br />
          Mircea Trofin,<br />
          Ramakrishna Upadrasta<br />
        </p>
      </td>
      <td>
        <p>
          <a href="#talk4">The Next 700 ML-Enabled Compiler Optimizations</a>
          <!-- <br/><span style="font-family: monospace;">[<a href="slides/RL4ReAl.pdf">slides</a>]</span> -->
        </p>
      </td>
      <td>
        <p>
          ML driven Compiler Optimizations<br />
          Infrastructure<br />
          Library<br />
          LLVM<br />
          MLIR<br />
          Pluto<br />
        </p>
      </td>
    </tr>
    <!-- Break -->
    <tr>
      <td>
        <p>9:50 - 10:00 (10 min)</p>
      </td>
      <td>
        <p> - </p>
      </td>
      <td>
        <p> Coffee break </p>
      </td>
      <td>
        <p> - </p>
      </td>
    </tr>
    <!-- Talk 5 -->
    <tr>
      <td>
        <p>10:00 - 10:30 (30 min)</p>
      </td>
      <td>
        <p>
          Rafael Andres Herrera Guaitero,<br />
          Rodrigo Ceccato de Freitas,<br />
          Rémy Neveu,<br />
          Jose Manuel Monsalve Diaz<br />
        </p>
      </td>
      <td>
        <p>
          <a href="#talk5">Unveiling the Power of Heterogeneous Computing: A Brief Dive into Host and Target Tasks with OpenMP LLVM</a>
          <!-- <br/><span style="font-family: monospace;">[<a href="slides/RL4ReAl.pdf">slides</a>]</span> -->
        </p>
      </td>
      <td>
        <p>
          Heterogeneous Computing<br />
          Device Offloading<br />
          OpenMP<br />
          LLVM<br />
          Accelerators<br />
        </p>
      </td>
    </tr>
    <!-- Talk 6 -->
    <tr>
      <td>
        <p>10:30 - 10:55 (25 min)</p>
      </td>
      <td>
        <p>
          Tobias Schwarz,<br />
          Alexis Engelke<br />
        </p>
      </td>
      <td>
        <p>
          <a href="#talk6">Building a Fast Back-end for LLVM-IR</a>
          <!-- <br/><span style="font-family: monospace;">[<a href="slides/RL4ReAl.pdf">slides</a>]</span> -->
        </p>
      </td>
      <td>
        <p>
          LLVM<br />
          Back-end<br />
          Fast compilation<br />
        </p>
      </td>
    </tr>
    <!-- Talk 7 -->
    <tr>
      <td>
        <p>10:55 - 11:20 (25 min)</p>
      </td>
      <td>
        <p>
          Guray Ozen<br />
        </p>
      </td>
      <td>
        <p>
          <a href="#talk7">Targeting NVIDIA Hopper using MLIR</a>
          <!-- <br/><span style="font-family: monospace;">[<a href="slides/RL4ReAl.pdf">slides</a>]</span> -->
        </p>
      </td>
      <td>
        <p>
          Code generation<br />
          MLIR<br />
          GPU<br />
        </p>
      </td>
    </tr>
    <!-- Talk 8 -->
    <tr>
      <td>
        <p>11:20 - 11:45 (25 min)</p>
      </td>
      <td>
        <p>
          George Stelle,<br />
          Tarun Prabhu,<br />
          Pat McCormick<br />
        </p>
      </td>
      <td>
        <p>
          <a href="#talk8">Dominance is not a Tree: Towards More Precise Dominance Relations</a>
          <!-- <br/><span style="font-family: monospace;">[<a href="slides/RL4ReAl.pdf">slides</a>]</span> -->
        </p>
      </td>
      <td>
        <p>
          Dominance<br />
          Single Static Assignment<br />
          Concurrency<br />
          Optimizations<br />
        </p>
      </td>
    </tr>
    <!-- Talk 9 -->
    <tr>
      <td>
        <p>11:45 - 12:05 (25 min)</p>
      </td>
      <td>
        <p>
          Ivan Ivanov,<br />
          Jens Domke,<br />
          Toshio Endo,<br />
          Johannes Doerfert<br />
        </p>
      </td>
      <td>
        <p>
          <a href="#talk9">Automatic Parallelization and OpenMP Offloading of Fortran</a>
          <!-- <br/><span style="font-family: monospace;">[<a href="slides/RL4ReAl.pdf">slides</a>]</span> -->
        </p>
      </td>
      <td>
        <p> 
          Fortran<br />
          OpenMP<br />
          Offloading<br />
        </p>
      </td>
    </tr>
    <!-- Closing remarks -->
    <tr>
      <td>
        <p>12:06 - 12:15 (10 min)</p>
      </td>
      <td>
        <p>
          <a href="https://www.linkedin.com/in/josemonsalve2/">Jose M Monsalve Diaz</a><br />
          <a href="https://www.linkedin.com/in/shiltian/">Shilei Tian</a><br />
          <a href="https://www.linkedin.com/in/johannes-doerfert-3a0770a2">Johannes Doerfert</a><br />
          <a href="https://twitter.com/_hiraditya_">Aditya Kumar</a><br />
          <a href="https://www.linkedin.com/in/randres-herrera/">Rafael A Herrera Guaitero</a>
        </p>
      </td>
      <td>
        <p>Closing Remarks</p>
      </td>
      <td>
        <p>Getting feedback</p>
      </td>
    </tr>
  </tbody>
</table>


<div class="www_sectiontitle">Abstracts</div>

<h3 id="talk1" class="cgo-title" style="font-weight: bold;">Map LLVM Values to corresponding source level expression<br/><span style="font-size: x-small;"><a href="#workshop-schedule"> &#9650; back to schedule</a></span></h3>
<h4>Shivam Kunwar</h4>
<!-- <h5><sup>1</sup>Pacific Northwest National Laboratory</h5> -->
<p>
  The primary objective of this project is to enhance the effectiveness of compiler-generated remarks and analysis reports for code optimization. These messages, while often comprehensive, lack direct connections to the corresponding source-level expressions. The goal is to bridge this gap by utilizing LLVM's intrinsic functions, which establish mappings between LLVM program entities and source-level expressions. The project specifically focuses on utilizing these intrinsic functions to generate or derive source expressions from LLVM values. This functionality is particularly important for enhancing memory access optimizations, including the reporting of memory access dependences that hinder vectorization.
</p>

<h3 id="talk2" class="cgo-title" style="font-weight: bold;">Using LLVM to inspect, and fix, the Physical Structure of a Large Scale Software - The Codevis Project<br/><span style="font-size: x-small;"><a href="#workshop-schedule"> &#9650; back to schedule</a></span></h3>
<h4>Joachim Meyer<sup>1, 2</sup></h4>
<h5><sup>1</sup>KDE, <sup>2</sup>Codethink</h5>
<p>
  Codevis is an open source tool that enables the user to study, analyse, and fix large scale software architecture flaws.

  The software currently understands C, c++ and Fortran. Codevis' main use case is to display relationship graphs between libraries, structures (such as classes or pure "c" structures), functions (including traits, functions or methods), and files. Codevis offers several tools that help find problems on large scale designs, such as a `Knowledge Island` (a visualisation that showcases who originates the source code per file, module, class) to `Find Cycles`. We know old software usually grows organically, and without the knowledge we have today, cycles probably exist that make this an even more tangled ball of yarn.

  Codevis aims to help corporations visualise all their software architecture in one single tool. This ensures faster action can be taken during development, or faster action can be taken during architecture decision-making.

  LLVM is a core part of this project for the C++ and Fortran parser. It has been proven to work. It fixes architectural issues within the KDE Frameworks Libraries - a collection of 80+ libraries combinning millions of lines of code.
</p>

<h3 id="talk3" class="cgo-title" style="font-weight: bold;">Practical Use of BOLT<br/><span style="font-size: x-small;"><a href="#workshop-schedule"> &#9650; back to schedule</a></span></h3>
<h4>Amir Ayupov<sup>1</sup></h4>
<h5><sup>1</sup>Meta</h5>
<p>
  BOLT is a binary optimizer for ELF binaries and is a part of LLVM project. Utilizing sample-based profiling, BOLT boosts the performance even for highly optimized binaries built with both profile-guided optimizations (PGO) and link-time optimizations (LTO).
  BOLT has been demonstrated to be effective for a number of workloads spanning from HHVM to Clang, Python, Rust, MySQL, and Chromium, and has features enabling its use in various environments. This talk focuses on practical aspects of BOLT application through profile collection, use of BOLT optimizations and flags for specific use cases, interaction with compiler PGO, and usage in continuous profiling scenarios.
</p>

<h3 id="talk4" class="cgo-title" style="font-weight: bold;">The Next 700 ML-Enabled Compiler Optimizations<br/><span style="font-size: x-small;"><a href="#workshop-schedule"> &#9650; back to schedule</a></span></h3>
<h4>Venkatakeerthy S<sup>1</sup>, Siddharth Jain<sup>1</sup>, Umesh Kalvakuntla<sup>1</sup>, Pranav Sai Gorantla<sup>1</sup>, Rajiv Shailesh Chitale<sup>1</sup>, Eugene Brevdo<sup>2</sup>, Albert Cohen<sup>2</sup>, Mircea Trofin<sup>2</sup> and Ramakrishna Upadrasta<sup>1</sup></h4>
<h5><sup>1</sup>IIT Hyderabad, <sup>2</sup>Google DeepMind</h5>
<p>
  There is a growing interest in enhancing compiler optimizations with ML models, yet interactions between compilers and ML frameworks remain challenging. Some optimizations require tightly coupled models and compiler internals, raising issues with modularity, performance and framework independence. Practical deployment and transparency for the end-user are also important concerns. We propose MLCompiler-Bridge to enable ML model development within a traditional Python framework while making end-to-end integration with an optimizing compiler possible and efficient. We evaluate it on both research and production use cases, for training and inference, over several optimization problems, multiple compilers and its versions, and gym infrastructures.
</p>

<h3 id="talk5" class="cgo-title" style="font-weight: bold;">Unveiling the Power of Heterogeneous Computing: A Brief Dive into Host and Target Tasks with OpenMP LLVM<br/><span style="font-size: x-small;"><a href="#workshop-schedule"> &#9650; back to schedule</a></span></h3>
<h4>Rafael Andres Herrera Guaitero<sup>1</sup>, Rodrigo Ceccato de Freitas<sup>2</sup>, Rémy Neveu<sup>3</sup> and Jose Manuel Monsalve Diaz<sup>3</sup></h4>
<h5><sup>1</sup>University of Delaware, <sup>2</sup>UNICAMP, <sup>3</sup>Argonne National Lab</h5>
<p>
  This session offers a concise overview of achieving heterogeneous computing through OpenMP. This presentation aims to explain the current state of the implementation and provide guidance to other developers, especially those who are new, on how to get started and contribute to LLVM's OpenMP host and target task support. We look at the role of the runtime system interface and its implementation, providing insights into the essential components that drive heterogeneous computing. We also discuss the current RFC of the offloading runtime project and the plans to use it universally. To help a practical understanding, we finish the session with a simple example that shows how to compile and execute heterogeneous code using the LLVM framework.
</p>

<h3 id="talk6" class="cgo-title" style="font-weight: bold;">Building a Fast Back-end for LLVM-IR<br/><span style="font-size: x-small;"><a href="#workshop-schedule"> &#9650; back to schedule</a></span></h3>
<h4>Tobias Schwarz<sup>1</sup> and Alexis Engelke<sup>1</sup></h4>
<h5><sup>1</sup>Technical University of Munich</h5>
<p>
  Low compilation times of unoptimized builds are important for developer productivity and especially for fast start-up just-in-time compilation. LLVM's back-end is an often-cited problem for these use cases, with a substantial portion of the compile-time being spent for rewriting the program code multiple times.

  We develop a completely new LLVM back-end for a commonly used subset of LLVM-IR (e.g., typical output of Clang) targeting x86-64 without using the existing back-end infrastructure. Instead, we generate machine code with just two passes over the input IR without any further IR. This way, on the SPECint 2017 benchmarks, we achieve a ~10x compile-time speed-up over the LLVM -O0 back-end with a run-time slowdown in the range of 0-30%. Instead of building a custom IR, we start from LLVM-IR as this allows adopting our compiler as fast baseline without code changes while still providing an easy path to optimized compilation.

  In this talk, we describe our approach and related challenges and experiences when building an entirely new, performance-focused LLVM back-end from scratch.
</p>

<h3 id="talk7" class="cgo-title" style="font-weight: bold;">Targeting NVIDIA Hopper using MLIR<br/><span style="font-size: x-small;"><a href="#workshop-schedule"> &#9650; back to schedule</a></span></h3>
<h4>Guray Ozen<sup>1</sup></h4>
<h5><sup>1</sup>Google Research</h5>
<p>
  This talk explores how to make the most of the NVIDIA Hopper Tensor Core by using its new hardware features effectively. Even with these advanced features, the challenge lies in efficiently using them, especially when creating fast General Matrix Multiply (GEMM) kernels.

  The ongoing research focuses on integrating the features of the NVIDIA Hopper Architecture GPU into the MLIR compiler. The main goal is to turn MLIR into a strong compiler that can unlock the best performance from GPUs. The talk discusses how to implement important elements, such as the Tensor Memory Accelerator (TMA), warp-group level tensor core instructions, and transactional barriers.

  Several features have been implemented to GPU, NVGPU, and NVVM dialects. The GPU dialect is where we launch the kernel, NVVM dialect is where we generate PTX assembly, and NVGPU dialect is where we can create efficient kernels at a higher level. The talk covers a detailed discussion of these dialects and how they contribute to optimizing the performance of the NVIDIA Hopper Architecture.
</p>

<h3 id="talk8" class="cgo-title" style="font-weight: bold;">Dominance is not a Tree: Towards More Precise Dominance Relations<br/><span style="font-size: x-small;"><a href="#workshop-schedule"> &#9650; back to schedule</a></span></h3>
<h4>George Stelle<sup>1</sup>, Tarun Prabhu<sup>1</sup>, Pat McCormick<sup>1</sup></h4>
<h5><sup>1</sup>Los Alamos National Laboratory</h5>
<p>
  In LLVM and other modern compilers, single static assignment (SSA) is a crucial theory for internal representations, enabling optimizations in the presence of imperative code. A fundamental function of SSA is calculating and using dominance relations to determine where immutable variables can be referenced. Dominator trees have historically been a good approximation of the dominator relation and efficiently computable. However, there are programs for which the dominator tree fails to capture precise dominance relations, preventing optimizations. In this work, we give examples of these kinds of programs, and show how removing the restriction to tree relations enables more precise dominance relations, therefore enabling more optimization. We discuss how one can use properties of SSA to implement a more general dominance relation using a small set of trees corresponding to shared branches, which we call a dominator grove. We present a work-in-progress implementation of a dominator grove in LLVM, along with some of the current hurdles in modifying the existing analyses and transformations to be sound in the presence of non-tree dominance relations. Using the implementation, we collect empirical data on the frequency of non-tree dominance relations in real code. We present some basic formal properties of the approach, and end with a discussion of future work, including concurrent extensions to SSA theory.
</p>

<h3 id="talk9" class="cgo-title" style="font-weight: bold;">Automatic Parallelization and OpenMP Offloading of Fortran<br/><span style="font-size: x-small;"><a href="#workshop-schedule"> &#9650; back to schedule</a></span></h3>
<h4>Iva Ivanov<sup>1, 2</sup>, Jens Domke<sup>3</sup>, Toshio Endo<sup>1</sup>, Johannes Doerfert<sup>2</sup></h4>
<h5><sup>1</sup>Tokyo Institute of Technology, <sup>2</sup>Lawrence Livermore National Laboratory, <sup>3</sup>RIKEN Center for Computational Science (R-CCS)</h5>
<p>
  The most substantial compute power found in most modern HPC systems is in their accelerators, namely GPUs. Thus, it is extremely important to utilize them in order to maximize performance of scientific computing applications. Fortran is still prevalent in the scientific community and there are vast amounts of important existing applications written in it, however, legacy Fortran code was not written with accelerators in mind, so enabling scientists to easily make use of modern hardware with minimal effort is an important goal.

  OpenMP has been widely used as a way to accelerate these programs, and the 6.0 version of the standard which is scheduled to be released in late 2024 introduces a new directive with this goal in mind, called coexecute. It allows the programmer to instruct the compiler to automatically parallelize and offload a sequence of array operations and calls to intrinsic functions. This requires extensive compiler transformations such as splitting device kernels and parallelization of loops, which we implement in LLVM's MLIR based compiler, Flang. We show how automatic parallelization and offloading of existing fortran code to accelerators is possible with just simple annotations from the programmer.
</p>

<div class="www_sectiontitle">Call for Speakers</div>
<p>
  We invite speakers from academia and industry to present their work on the following list of topics (including and not
  limited to:)
</p>
<ul>
  <li>Improving performance and code-size of applications built by LLVM toolchains</li>
  <li>Improving performance of LLVM's runtime libraries</li>
  <li>Improving the security of generated code</li>
  <li>Any tools or products developed by using one of the libraries in LLVM infrastructure</li>
  <li>Performance tracking over time</li>
  <li>Compiler flags, annotations and remarks to understand and improve performance</li>
  <li>Any other topic related to improving and maintaining the performance and quality of LLVM generated code</li>
</ul>
<p>

  While the primary focus of the workshop is on these topics, we welcome
  any submission related to the LLVM-project, its sub-projects (clang,
  mlir, lldb, Polly, lld, openmp, pstl, compiler-rt, etc.), as well as
  their use in industry and academia.
</p>

<p>We are looking for:</p>
<ul>
  <li>keynote speakers (30-60minutes),</li>
  <li>technical presentations (30 minutes plus questions and discussion),</li>
  <li>tutorials (30-60minutes),</li>
  <li>panels (30-60minutes),</li>
  <li>BOFs (30-60minutes)</li>
</ul>

<p>
  Proposals should provide sufficient information for the review
  committee to be able to judge the quality of the submission. Proposals
  can be submitted under the form of an extended abstract, full paper,
  or slides. Accepted presentations will be presented
  online. The presentations will be publicly available on
  <a href="https://llvm.org/devmtg/">https://llvm.org/devmtg/</a>
</p>

<p>
  In case of any queries please reach out to the workshop organizers: Johannes
  Doerfert (jdoerfert at llnl.gov), Aditya (hiraditya at msn.com),
  Jose M Monsalve Diaz (jmonsalvediaz at anl.gov),
  Shilei Tian (i at tianshilei.me), or Rafael (rafaelhg at udel.edu).
</p>

<h4>What types of people attend?</h4>
<ul>
  <li>Active developers of projects in the LLVM Umbrella (LLVM core, Clang, LLDB, libc++, compiler_rt, klee, lld,
    OpenMP, etc).</li>
  <li>Anyone interested in using these as part of another project.</li>
  <li>Students and Researchers.</li>
  <li>Compiler, programming language, and runtime enthusiasts.</li>
  <li>Those interested in using compiler and toolchain technology in novel and interesting ways.</li>
</ul>


<h4>Panels</h4>
Panel sessions are guided discussions about a specific topic. The panel consists of ~3 developers who discuss a topic
through prepared questions from a moderator. The audience is also given the opportunity to ask questions of the panel.

<h4>Birds of a Feather (BoF)</h4>
A BoF session, an informal meeting at conferences, where the attendees group together based on a shared interest and
carry out discussions without any pre-planned agenda.

<h4>Technical Talks</h4>
These 20-30 minute talks cover all topics from core infrastructure talks, to project's using LLVM's infrastructure.
Attendees will take away technical information that could be pertinent to their project or general interest.

<h4>Tutorials</h4>
Tutorials are 30-60 minute sessions that dive down deep into a technical topic. Expect in depth examples and
explanations.

<div class="www_sectiontitle" id="coc">Code of Conduct</div>
<p>The LLVM Foundation is dedicated to providing an inclusive and safe
  experience for everyone. We do not tolerate harassment of participants in any
  form. By registering for this event, we expect you to have read and agree to
  the <a href="http://llvm.org/docs/CodeOfConduct.html">LLVM Code of Conduct</a>.
</p>
<p>
  We also adhere to the <a href="https://conf.researchr.org/attending/cgo-2024/code-of-conduct" target="_blank"> Code of
    Conduct use by CGO </a>
</p>


<!-- *********************************************************************** -->
<hr>

<!--#include virtual="../../footer.incl" -->
